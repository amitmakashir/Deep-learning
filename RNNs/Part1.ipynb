{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Part1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amitmakashir/Deep-learning/blob/master/Part1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sAJ5jnRu7x-c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import random\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)\n",
        "\n",
        "from timeit import default_timer as timer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2nShD8au_LUK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Network structure\n",
        "hidden_units = [1024,1024,1024,1024,1024]     # hidden_units[0] => 1024 hidden units in the first layer \n",
        "output_nodes = 10\n",
        "input_nodes = 784\n",
        "\n",
        "no_of_train_images = len(mnist.train.images)\n",
        "\n",
        "# Hyperparameters\n",
        "learning_rate = 0.001\n",
        "epochs = 100\n",
        "minibatch_size = 350\n",
        "num_iters = no_of_train_images // minibatch_size"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YClFxZSK_RO9",
        "colab_type": "code",
        "outputId": "1671bad2-da69-4116-8df5-bf5df5925849",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "# Create placeholders for input X and labels y\n",
        "x = tf.placeholder(tf.float32, [None, 784])\n",
        "y_true = tf.placeholder(tf.float32, [None, 10])\n",
        "\n",
        "\n",
        "# Constructs a neural network with the specified inputs, outputs and hidden layers\n",
        "# hidden_units is a list containing hidden units at every hidden layer\n",
        "# the length of hidden_units list determines the no of hidden layers\n",
        "# the output_nodes determine the no of classes to be predicted\n",
        "# Currently use the \"He\" initialization for initializing the weights\n",
        "def construct_network(input_nodes, output_nodes, hidden_units):\n",
        "    no_of_hidden_layers = len(hidden_units)\n",
        "    W = []\n",
        "    b = []\n",
        "\n",
        "    initializer = tf.contrib.layers.variance_scaling_initializer()\n",
        "  \n",
        "    for i in range(no_of_hidden_layers + 1):\n",
        "        if i == 0:   # First layer\n",
        "            w = tf.Variable(initializer([input_nodes, hidden_units[i]]), dtype=tf.float32)\n",
        "            bias = tf.Variable(tf.random_normal([hidden_units[i]]), dtype=tf.float32)\n",
        "      \n",
        "        elif i == no_of_hidden_layers:  # Last layer\n",
        "            w = tf.Variable(initializer([hidden_units[i-1], output_nodes]), dtype=tf.float32)\n",
        "            bias = tf.Variable(tf.random_normal([output_nodes]), dtype=tf.float32)\n",
        "      \n",
        "        else:  # Hidden layers\n",
        "            w = tf.Variable(initializer([hidden_units[i-1], hidden_units[i]]), dtype=tf.float32)\n",
        "            bias = tf.Variable(tf.random_normal([hidden_units[i]]), dtype=tf.float32)\n",
        "\n",
        "        W.append(w)\n",
        "        b.append(bias)\n",
        "  \n",
        "    return W,b\n",
        "\n",
        "\n",
        "# Once the network is constructed, pass the input X in the network.\n",
        "# Apply suitable activations in the hidden layers.\n",
        "# Don't apply any activations on the last layer in this function as this function\n",
        "# could be used for classification as well as regression problems\n",
        "def solve(x,W,b):\n",
        "    n = len(W)\n",
        "    y = []\n",
        "\n",
        "    for i in range(n): # First layer\n",
        "        if i == 0:\n",
        "            y.append(tf.nn.relu(tf.matmul(x, W[i]) + b[i]))\n",
        "\n",
        "        elif i == n-1: # Last layer\n",
        "            y.append(tf.matmul(y[i-1], W[i]) + b[i])\n",
        "\n",
        "        else: # Hidden layers\n",
        "            y.append(tf.nn.relu(tf.matmul(y[i-1], W[i]) + b[i]))\n",
        "  \n",
        "    return y\n",
        "\n",
        "\n",
        "# Return a given no of random samples from the data X and y \n",
        "def randomly_sample(X,y,no_of_samples):\n",
        "    # Generate random indices for the samples\n",
        "    indices = random.sample(range(0, len(X)), no_of_samples)\n",
        "\n",
        "    samples_X = np.array([X[i] for i in indices])\n",
        "    samples_label = np.array([y[i] for i in indices])\n",
        "\n",
        "    samples_label_argmax = np.argmax(samples_label,1)\n",
        "\n",
        "    return samples_X,samples_label_argmax\n",
        "\n",
        "\n",
        "def feedForward(x,y_true,W,b):\n",
        "    ## \"y\" is the output of the network. Pass it through the softmax function\n",
        "    y = solve(x,W,b)\n",
        "    y_pred = tf.nn.softmax(y[-1])\n",
        "\n",
        "    ## Calculate the accuracy of this classifier by calculating % of correctly classified images\n",
        "    correct_prediction = tf.equal(tf.argmax(y_pred,1), tf.argmax(y_true,1))\n",
        "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "    \n",
        "    return y,accuracy\n",
        "\n",
        "        \n",
        "\n",
        "## Main program starts from here\n",
        "  \n",
        "## Construct the network using the given configuration \n",
        "W,b = construct_network(input_nodes, output_nodes, hidden_units) \n",
        "\n",
        "## \"y\" is the output of the network. Pass it through the softmax function\n",
        "y = solve(x,W,b)\n",
        "y_pred = tf.nn.softmax(y[-1])\n",
        "\n",
        "\n",
        "## Define the cost function to be optimized and the optimizer to be used\n",
        "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=y[-1],labels=y_true))\n",
        "train_step = tf.train.AdamOptimizer(learning_rate).minimize(cost)\n",
        "\n",
        "### Start the session\n",
        "sess = tf.InteractiveSession()\n",
        "tf.global_variables_initializer().run()\n",
        "\n",
        "## Calculate the accuracy of this classifier by calculating % of correctly classified images\n",
        "correct_prediction = tf.equal(tf.argmax(y_pred,1), tf.argmax(y_true,1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "test_accuracy = 0\n",
        "\n",
        "## Running the neural network\n",
        "for e in range(epochs):\n",
        "    if test_accuracy > 0.98:\n",
        "        break\n",
        "            \n",
        "    for _ in range(num_iters):\n",
        "        batch_xs, batch_ys = mnist.train.next_batch(minibatch_size)\n",
        "        sess.run(train_step, feed_dict={x: batch_xs, y_true: batch_ys})\n",
        "  \n",
        "        # Calculate the test accuracy after every epoch\n",
        "        test_accuracy = sess.run(accuracy, feed_dict={x: mnist.test.images, y_true: mnist.test.labels})\n",
        "        if test_accuracy > 0.98:\n",
        "            break\n",
        "\n",
        "print(\"Accuracy on Test images: \"+ str(test_accuracy))\n",
        "\n",
        "# Weights\n",
        "W = sess.run(W, feed_dict={x: batch_xs, y_true: batch_ys})"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "Accuracy on Test images: 0.9812\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gNB9HixX5Zum",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use SVD to get singular values of the weight matrix. Choose only the top \"D\"\n",
        "# values from the singular vector and create a diagonal matrix from it. Multiply \n",
        "# it to u and v to reconstruct the weight matrix again. As we only choose the \"D\" \n",
        "# values the reconstructed matrix would sparser than the original matrix\n",
        "def compressWeight(w,D):\n",
        "    '''\n",
        "    u => (784,784)\n",
        "    s => (784,)\n",
        "    v => (1024,1024)\n",
        "\n",
        "    After choosing \"D\" values from s:\n",
        "    s => (20,)\n",
        "\n",
        "    Converting s to diagonal matrix:\n",
        "    s => (20,20)\n",
        "\n",
        "    Multiplying u,s and v\n",
        "    w => (784,20) * (20,20) * (20,1024)\n",
        "    '''\n",
        "    u,s,v =  np.linalg.svd(w,full_matrices=True)\n",
        "  \n",
        "    if D == \"DFull\":\n",
        "        D = s.shape[0]\n",
        "        \n",
        "    w = np.matrix(u[:, :D]) * np.diag(s[:D]) * np.matrix(v[:, :D].T)\n",
        "\n",
        "    w = sess.run(tf.convert_to_tensor(w, np.float32))\n",
        "    return w \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aIF9SatHDrZ_",
        "colab_type": "text"
      },
      "source": [
        "## Q 1.5 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3FQXyiSn6yF0",
        "colab_type": "code",
        "outputId": "aca2f1e5-b5d4-4147-9cc8-ea61d1108a14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "D = [10, 20, 50, 100, 200,\"DFull\"]\n",
        "\n",
        "W_all = []\n",
        "\n",
        "for d in D:\n",
        "    W_new = []\n",
        "    \n",
        "    for i,w in enumerate(W): \n",
        "        if i == len(W)-1: # we are not compressing the last weight\n",
        "            W_new.append(w)\n",
        "        else:\n",
        "            W_new.append(compressWeight(w,d))\n",
        "    \n",
        "    # Push the newly reconstructed weights to the \"W_all\" list\n",
        "    W_all.append(W_new)\n",
        "    \n",
        "    start = timer()\n",
        "    # Run the feedforward on these weights\n",
        "    y_pred,test_accuracy = sess.run(feedForward(x,y_true,W_all[-1],b), feed_dict={x: mnist.test.images, y_true: mnist.test.labels})    \n",
        "    end = timer()\n",
        "    \n",
        "    print(\"For D = \",str(d),\", Test accuracy = \",str(test_accuracy),\", Time taken in seconds = \",str(round(end-start,4)))    "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "For D =  10 , Test accuracy =  0.1028 , Time taken in seconds =  0.4126\n",
            "For D =  20 , Test accuracy =  0.1028 , Time taken in seconds =  0.1813\n",
            "For D =  50 , Test accuracy =  0.1135 , Time taken in seconds =  0.4301\n",
            "For D =  100 , Test accuracy =  0.1135 , Time taken in seconds =  0.1791\n",
            "For D =  200 , Test accuracy =  0.1135 , Time taken in seconds =  0.182\n",
            "For D =  DFull , Test accuracy =  0.1135 , Time taken in seconds =  0.1827\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lOJ-nYAZw28d",
        "colab_type": "text"
      },
      "source": [
        "### 1.6 (Option 1)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xBOWd6XRgbCJ",
        "colab_type": "code",
        "outputId": "050e9d90-6a12-4daa-aacc-ae9be24027cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "# Save the pretrained weights for the analysis\n",
        "pretrained_W = W\n",
        "\n",
        "# Hyperparameters\n",
        "learning_rate = 0.001\n",
        "epochs = 100\n",
        "minibatch_size = 350\n",
        "num_iters = no_of_train_images // minibatch_size\n",
        "\n",
        "## Main program starts from here\n",
        "\n",
        "# Constructs a neural network with the specified inputs, outputs and hidden layers\n",
        "# hidden_units is a list containing hidden units at every hidden layer\n",
        "# the length of hidden_units list determines the no of hidden layers\n",
        "# the output_nodes determine the no of classes to be predicted\n",
        "# Currently use the \"He\" initialization for initializing the weights\n",
        "def construct_network_withSVD(input_nodes, output_nodes, hidden_units,pretrained_w):\n",
        "    no_of_hidden_layers = len(hidden_units)\n",
        "    W = []\n",
        "    b = []\n",
        "    D = 20\n",
        "    \n",
        "    initializer = tf.contrib.layers.variance_scaling_initializer()\n",
        "\n",
        "    for i in range(no_of_hidden_layers + 1):\n",
        "        if i == 0:   # First layer\n",
        "            # w = tf.Variable(initializer([input_nodes, hidden_units[i]]), dtype=tf.float32)\n",
        "            bias = tf.Variable(tf.random_normal([hidden_units[i]]), dtype=tf.float32)\n",
        "                    \n",
        "            u, s, v = np.linalg.svd(pretrained_w[i],full_matrices=True)    \n",
        "            \n",
        "            u = tf.Variable(u[:,:D], dtype=tf.float32)\n",
        "            v_hat = tf.Variable(tf.matmul(tf.linalg.diag(s[:D]) , v[:, :D],adjoint_b=True), dtype=tf.float32)\n",
        "            w = tf.matmul(u,v_hat)\n",
        "\n",
        "        elif i == no_of_hidden_layers:  # Last layer\n",
        "            w = tf.Variable(initializer([hidden_units[i-1], output_nodes]), dtype=tf.float32)\n",
        "            bias = tf.Variable(tf.random_normal([output_nodes]), dtype=tf.float32)\n",
        "\n",
        "        else:  # Hidden layers\n",
        "            w = tf.Variable(initializer([hidden_units[i-1], hidden_units[i]]), dtype=tf.float32)\n",
        "            bias = tf.Variable(tf.random_normal([hidden_units[i]]), dtype=tf.float32)\n",
        "            \n",
        "            s,u,v = tf.linalg.svd(w,full_matrices=True)\n",
        "            \n",
        "            u = tf.Variable(u[:,:D], dtype=tf.float32)\n",
        "            v_hat = tf.Variable(tf.matmul(tf.linalg.diag(s[:D]) , v[:, :D],adjoint_b=True), dtype=tf.float32)\n",
        "            w = tf.matmul(u,v_hat)\n",
        "    \n",
        "        W.append(w)\n",
        "        b.append(bias)\n",
        "    \n",
        "    return W,b\n",
        "\n",
        "\n",
        "# Once the network is constructed, pass the input X in the network.\n",
        "# Apply suitable activations in the hidden layers.\n",
        "# Don't apply any activations on the last layer in this function as this function\n",
        "# could be used for classification as well as regression problems\n",
        "def solve_withSVD(x,W,b):\n",
        "    n = len(W)\n",
        "    y = []\n",
        "\n",
        "    for i in range(n): # First layer\n",
        "        if i == 0:\n",
        "            y.append(tf.nn.relu(tf.matmul(x, W[i]) + b[i]))\n",
        "\n",
        "        elif i == n-1: # Last layer\n",
        "            y.append(tf.matmul(y[i-1],W[i]) + b[i])\n",
        "\n",
        "        else: # Hidden layers\n",
        "            y.append(tf.nn.relu(tf.matmul(y[i-1], W[i]) + b[i]))\n",
        "  \n",
        "    return y\n",
        "\n",
        "## Construct the network using the given configuration \n",
        "W,b = construct_network_withSVD(input_nodes, output_nodes, hidden_units,pretrained_W) \n",
        "\n",
        "## \"y\" is the output of the network. Pass it through the softmax function\n",
        "y = solve_withSVD(x,W,b)\n",
        "y_pred = tf.nn.softmax(y[-1])\n",
        "\n",
        "## Define the cost function to be optimized and the optimizer to be used\n",
        "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=y[-1],labels=y_true))\n",
        "train_step = tf.train.AdamOptimizer(learning_rate).minimize(cost)\n",
        "\n",
        "## Calculate the accuracy of this classifier by calculating % of correctly classified images\n",
        "correct_prediction = tf.equal(tf.argmax(y_pred,1), tf.argmax(y_true,1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "\n",
        "tf.global_variables_initializer().run()\n",
        "\n",
        "test_accuracy = 0\n",
        "\n",
        "## Running the neural network\n",
        "for e in range(epochs):\n",
        "    if test_accuracy > 0.97:\n",
        "        break \n",
        "    for _ in range(num_iters):\n",
        "        batch_xs, batch_ys = mnist.train.next_batch(minibatch_size)\n",
        "        sess.run(train_step, feed_dict={x: batch_xs, y_true: batch_ys})\n",
        "  \n",
        "        # Calculate the test accuracy after every epoch\n",
        "        test_accuracy = sess.run(accuracy, feed_dict={x: mnist.test.images, y_true: mnist.test.labels})\n",
        "        if test_accuracy > 0.97:\n",
        "            break\n",
        "    \n",
        "print(\"Accuracy on Test images: \"+ str(test_accuracy))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0 , Acc =  0.9134\n",
            "Epoch: 1 , Acc =  0.9426\n",
            "Epoch: 2 , Acc =  0.9567\n",
            "Epoch: 3 , Acc =  0.961\n",
            "Epoch: 4 , Acc =  0.9647\n",
            "Epoch: 5 , Acc =  0.9706\n",
            "Accuracy on Test images: 0.9706\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oD87WzZ1LQlM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sess.close()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}