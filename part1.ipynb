{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "part1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amitmakashir/Deep-learning/blob/master/part1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EbxI0WOEdzlb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import librosa\n",
        "import math\n",
        "import pandas\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "swFVPuXwdc_I",
        "colab_type": "code",
        "outputId": "2a2d3962-a8df-4eff-9b11-7153a4ec7d64",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Training data\n",
        "\n",
        "# S is the clean file\n",
        "s, sr = librosa.load('train_clean_male.wav', sr=None)\n",
        "S = librosa.stft(s, n_fft=1024, hop_length=512)\n",
        "print(sr)\n",
        "# X is the dirty file\n",
        "sn, sr = librosa.load('train_dirty_male.wav', sr=None)\n",
        "X = librosa.stft(sn, n_fft=1024, hop_length=512)\n",
        "\n",
        "# X.shape => (513, 2459)\n",
        "X_mod = np.abs(X.T) # S_mod.shape => (2459, 513)\n",
        "\n",
        "# S.shape => (513, 2459)\n",
        "S_mod = np.abs(S.T) # S_mod.shape => (2459, 513)\n",
        "\n",
        "no_of_features = X_mod.shape[1]\n",
        "no_of_training_samples = X_mod.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "16000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "juavcrd6kpNB",
        "colab_type": "code",
        "outputId": "3e128e4a-b56c-41ea-9ac0-001c8d44988d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Testing data\n",
        "\n",
        "xt1, sr = librosa.load('test_x_01.wav', sr=None)\n",
        "X_test1 = librosa.stft(xt1, n_fft=1024, hop_length=512)\n",
        "xt2, sr = librosa.load('test_x_02.wav', sr=None)\n",
        "X_test2 = librosa.stft(xt2, n_fft=1024, hop_length=512)\n",
        "\n",
        "X_test1 = np.transpose(X_test1)\n",
        "X_test1_mod = np.abs(X_test1) # X_test1_mod.shape => (142,513)\n",
        "\n",
        "X_test2 = np.transpose(X_test2)\n",
        "X_test2_mod = np.abs(X_test2) # X_test2_mod.shape => (380, 513)\n",
        "\n",
        "print(X_test2_mod.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(380, 513)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dSbThqtJ4R2Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class miniBatch():\n",
        "  '''\n",
        "  Create mini Batches of the data for training the model\n",
        "  '''\n",
        "  def __init__(self,x,y,batch_size,random=True):\n",
        "    self.x = x\n",
        "    self.y = y\n",
        "    if random:\n",
        "      self.randomizeInputs()\n",
        "\n",
        "    self.rows = len(x)\n",
        "    self.batch_size = batch_size\n",
        "    self.curr_index = 0\n",
        "\n",
        "    # Total number of iterations\n",
        "    self.iters = math.ceil(self.rows/self.batch_size)\n",
        "    pass\n",
        "\n",
        "\n",
        "  def randomizeInputs(self):\n",
        "    '''\n",
        "    Shuffles the input data\n",
        "    '''\n",
        "    assert len(self.x) == len(self.y)\n",
        "    p = np.random.permutation(len(self.x))\n",
        "    self.x = self.x[p]\n",
        "    self.y = self.y[p]\n",
        "    return True\n",
        "\n",
        "\n",
        "  def nextBatch(self):\n",
        "    '''\n",
        "    Return the next batch of data\n",
        "    If the last batch is not of the batch size, give all the remaining elements\n",
        "    '''\n",
        "\n",
        "    if self.curr_index+self.batch_size >= self.rows:\n",
        "      batch_x = self.x[self.curr_index:]\n",
        "      batch_y = self.y[self.curr_index:]\n",
        "    else:\n",
        "      batch_x = self.x[self.curr_index:self.curr_index+self.batch_size]\n",
        "      batch_y = self.y[self.curr_index:self.curr_index+self.batch_size]\n",
        "\n",
        "    self.curr_index = self.curr_index+self.batch_size\n",
        "    return batch_x,batch_y\n",
        "\n",
        "    \n",
        "def crossValSet(x,y,size):\n",
        "  '''\n",
        "  Size will be in percent\n",
        "  Remove \"size\"% of data from the last as keep it for CV  \n",
        "  '''\n",
        "  no_of_elements = math.ceil(len(x)*(size/100))\n",
        "  \n",
        "  train_x = x[:-no_of_elements]\n",
        "  train_y = y[:-no_of_elements]\n",
        "  \n",
        "  cv_x = x[-no_of_elements:]\n",
        "  cv_y = y[-no_of_elements:]    \n",
        "  return train_x,train_y,cv_x,cv_y\n",
        "\n",
        "\n",
        "def transform_input(x):\n",
        "  return x.reshape((-1,513,1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PslgkqbcOkL4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Hyperparameters\n",
        "epochs = 2\n",
        "# epochs = 1\n",
        "\n",
        "learning_rate = 0.0002\n",
        "batch_size = 128\n",
        "cv_size = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2ktuRbi-f8fL",
        "colab": {}
      },
      "source": [
        "# Create placeholders for input X and labels y\n",
        "x = tf.placeholder(tf.float32, [None,513,1])\n",
        "y_true = tf.placeholder(tf.float32, [None,513])\n",
        "\n",
        "    \n",
        "# Architecture of Network\n",
        "layer1 = { \"type\":\"conv2d\",\n",
        "            \"filters\":8,\n",
        "            \"kernel_size\":4,\n",
        "         }\n",
        "\n",
        "\n",
        "layer2 = { \"type\":\"conv2d\",\n",
        "            \"filters\":16,\n",
        "            \"kernel_size\":3,\n",
        "         }\n",
        "\n",
        "\n",
        "layer3 = { \"type\":\"conv2d\",\n",
        "            \"filters\":32,\n",
        "            \"kernel_size\":2,\n",
        "         }\n",
        "\n",
        "\n",
        "layer4 = { \"type\":\"maxpool\",\n",
        "            \"pool_size\":2,\n",
        "            \"padding\":'valid'\n",
        "         }\n",
        "\n",
        "\n",
        "layers = [layer1,layer2,layer3,layer4]\n",
        "\n",
        "\n",
        "\n",
        "def construct_network(input_x,layers):\n",
        "    '''\n",
        "    Consruct a network depending on the configuration\n",
        "    \n",
        "    Current configuration:\n",
        "    Conv2d -> Conv2d -> Conv2d -> MaxPool -> Reshape -> \n",
        "    Fully Connected -> Dropout -> Fully Connected \n",
        "    '''\n",
        "    constructed_network = []\n",
        "    \n",
        "    last_conv_filter = 0\n",
        "    no_of_maxpool = 0\n",
        "    \n",
        "    # He initialization\n",
        "    he_initializer = tf.contrib.layers.variance_scaling_initializer()\n",
        "    \n",
        "    for layer in layers:\n",
        "      \n",
        "      if len(constructed_network) == 0: # This is the First layer\n",
        "        this_input = input_x\n",
        "      else:\n",
        "        this_input = constructed_network[-1]\n",
        "          \n",
        "      if layer[\"type\"] == \"conv2d\":\n",
        "        current_layer = tf.layers.conv1d( \n",
        "                          inputs = this_input,\n",
        "                         filters = layer[\"filters\"],\n",
        "                         kernel_size = layer[\"kernel_size\"],\n",
        "                         strides = 1,\n",
        "                         padding = \"SAME\",\n",
        "                         kernel_initializer = he_initializer,\n",
        "                         activation = tf.nn.relu\n",
        "                        )\n",
        "        \n",
        "        last_conv_filter = layer[\"filters\"]\n",
        "        \n",
        "      elif layer[\"type\"] == \"maxpool\":\n",
        "        current_layer = tf.layers.max_pooling1d(\n",
        "                          inputs = this_input,\n",
        "                          pool_size = layer[\"pool_size\"],\n",
        "                          strides = layer[\"pool_size\"], # Same as pool size to not consider the same box twice\n",
        "                          padding='valid'\n",
        "                        )\n",
        "        \n",
        "        no_of_maxpool += 1\n",
        "      \n",
        "      # Push this layer to network\n",
        "      constructed_network.append(current_layer)\n",
        "    \n",
        "    \n",
        "    # Fully connected layer\n",
        "    # Reshape this layer3 to by flattening this tensor's last 2 dim\n",
        "    \n",
        "    flat_dimensions = (513//(2*no_of_maxpool))*last_conv_filter \n",
        "    \n",
        "    reshaped_layer = tf.reshape(\n",
        "        constructed_network[-1],\n",
        "        [-1,flat_dimensions],\n",
        "        )\n",
        "    \n",
        "    second_last_layer = tf.layers.dense(\n",
        "        inputs = reshaped_layer,\n",
        "        units = 1024,\n",
        "        activation = tf.nn.relu,\n",
        "        use_bias = True,\n",
        "        kernel_initializer = he_initializer,\n",
        "        bias_initializer = tf.zeros_initializer(),\n",
        "        kernel_regularizer = None,\n",
        "        bias_regularizer = None,\n",
        "        activity_regularizer = None,\n",
        "        kernel_constraint = None\n",
        "        )\n",
        "    \n",
        "    dropout_layer = tf.layers.dropout(second_last_layer,\n",
        "                      rate=0.30\n",
        "                     )\n",
        "    \n",
        "    last_layer = tf.layers.dense(\n",
        "        inputs = dropout_layer,\n",
        "        units = 513,\n",
        "        activation = tf.nn.relu,\n",
        "        use_bias = True,\n",
        "        kernel_initializer = he_initializer,\n",
        "        bias_initializer = tf.zeros_initializer(),\n",
        "        kernel_regularizer = None,\n",
        "        bias_regularizer = None,\n",
        "        activity_regularizer = None,\n",
        "        kernel_constraint = None\n",
        "        )\n",
        "    \n",
        "    constructed_network.append(last_layer)\n",
        "\n",
        "    return constructed_network\n",
        "\n",
        "\n",
        "\n",
        "constructed_network = construct_network(x,layers)\n",
        "y_pred = constructed_network[-1]\n",
        "\n",
        "## Define the cost function to be optimized and the optimizer to be used  \n",
        "cost = tf.losses.mean_squared_error(y_pred, y_true)\n",
        "train_step = tf.train.AdamOptimizer(learning_rate).minimize(cost)\n",
        "\n",
        "### Start the session\n",
        "sess = tf.InteractiveSession()\n",
        "tf.global_variables_initializer().run()\n",
        "\n",
        "\n",
        "# ====== Training the network ======  \n",
        "cross_validation_errors = []\n",
        "\n",
        "transformed_X = transform_input(X_mod)\n",
        "train_x,train_y,cv_x,cv_y = crossValSet(transformed_X,S_mod,cv_size)\n",
        "\n",
        "for e in range(epochs):\n",
        "    # Create minibatches and train data on it\n",
        "    mini_batch = miniBatch(train_x,train_y,batch_size)\n",
        "  \n",
        "    for iter in range(mini_batch.iters):\n",
        "        batch_x,batch_y = mini_batch.nextBatch()\n",
        "        sess.run(train_step, feed_dict={x: batch_x, y_true: batch_y})\n",
        "  \n",
        "    # After every epoch, check the CV error\n",
        "    cross_validation_errors.append(sess.run(cost, feed_dict={x: cv_x, y_true: cv_y}))\n",
        "\n",
        "  # ====== Training ends ======    \n",
        "\n",
        "\n",
        "## Running a feedforward on the test samples\n",
        "s_test_1 = sess.run(y_pred,feed_dict={x: transform_input(X_test1_mod)})\n",
        "s_test_2 = sess.run(y_pred,feed_dict={x: transform_input(X_test2_mod)})\n",
        "\n",
        "# for calculating SNR\n",
        "y_train = sess.run(y_pred,feed_dict={x: transform_input(X_mod)})\n",
        "\n",
        "sess.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "clCyucyWgQce",
        "colab_type": "code",
        "outputId": "ea2ad17a-1df6-4070-841c-32c2c023a448",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(s_test_1.shape)\n",
        "# Convert the output of test sample 1 to wav file\n",
        "output_1 = (X_test1/X_test1_mod) * s_test_1\n",
        "output_istft_1 = librosa.istft(output_1.T, hop_length=512, win_length=1024)\n",
        "librosa.output.write_wav('test_s_01_recons.wav',output_istft_1, sr)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(142, 513)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ou9MIAS0OPM2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert the output of test sample 2 to wav file\n",
        "output_2 = (X_test2/X_test2_mod) * s_test_2\n",
        "output_istft_2 = librosa.istft(output_2.T, hop_length=512, win_length=1024)\n",
        "librosa.output.write_wav('test_s_02_recons.wav', output_istft_2, sr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t7Ay_gFXSeNj",
        "colab_type": "code",
        "outputId": "1f140363-67a0-432f-8072-245f9330b4ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# y_train is the output of network\n",
        "s_train_pred = (X.T/X_mod)*y_train\n",
        "s_train = librosa.istft(s_train_pred.T, hop_length=512, win_length=1024)   \n",
        "len_s = s_train.shape[0]\n",
        "\n",
        "\n",
        "def calcSNR(s_pred_td,s_true_td):\n",
        "      if s_pred_td.shape[0] != s_true_td.shape[0]:\n",
        "        min_length = min(s_pred_td.shape[0],s_true_td.shape[0])\n",
        "        s_pred_td = s_pred_td[:min_length]\n",
        "        s_true_td = s_true_td[:min_length]\n",
        "      \n",
        "      signal = np.sum(np.square(s_true_td))\n",
        "      noise = np.sum(np.square(s_true_td - s_pred_td))\n",
        "      \n",
        "      snr = 10 * np.log10(signal/noise)\n",
        "      \n",
        "      return snr\n",
        "\n",
        "train_snr = calcSNR(s_train,s)\n",
        "print(\"SNR for the training audio file: \" + str(round(train_snr,3)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SNR for the training audio file: 6.093\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GCYEygzrLC5m",
        "colab_type": "code",
        "outputId": "16741656-f65a-44ca-9934-37080cfe3e02",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        }
      },
      "source": [
        "def error_plot(errors,no_of_points):\n",
        "  step = len(errors) // no_of_points\n",
        "  \n",
        "  err = [errors[i] for i in range(step,len(errors),step)]\n",
        "  \n",
        "  plt.plot(err)\n",
        "  plt.ylabel(\"MSE (Cross-validation)\")\n",
        "  plt.show()\n",
        "  \n",
        "  return errors[-1]\n",
        "\n",
        "error_plot(cross_validation_errors,30)\n",
        "print(\"Mean squared error for the last iteration (on CV set): \" + str(round(cross_validation_errors[-1],3)))  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-926dc1c0f1ab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0merror_plot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcross_validation_errors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Mean squared error for the last iteration (on CV set): \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcross_validation_errors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-20-926dc1c0f1ab>\u001b[0m in \u001b[0;36merror_plot\u001b[0;34m(errors, no_of_points)\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0mstep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mno_of_points\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0merr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: range() arg 3 must not be zero"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8FnGSYlcsYm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}